# IBP_based_XAI_AP_training
Explanation methods are used to supervise models with human specified saliency maps. 
Therefore, efficacy of the supervision depends on quality of explanation method. 

This is an attempt to loop-out explanation methods from supervision of saliency maps by using IBP to supervise.